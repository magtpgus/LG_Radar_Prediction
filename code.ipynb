{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D233hR4YBwI9"
   },
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:26:42.572919Z",
     "iopub.status.busy": "2022-09-04T06:26:42.572330Z",
     "iopub.status.idle": "2022-09-04T06:26:43.910450Z",
     "shell.execute_reply": "2022-09-04T06:26:43.909825Z",
     "shell.execute_reply.started": "2022-09-04T06:26:42.572856Z"
    },
    "id": "sUzKZqTuNrei"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('mode.chained_assignment',  None) # <==== 경고를 끈다\n",
    "\n",
    "filename = './train.csv'\n",
    "data_train = pd.read_csv(filename)\n",
    "\n",
    "filename = './test.csv'\n",
    "data_test = pd.read_csv(filename)\n",
    "\n",
    "filename = './y_feature_spec_info.csv'\n",
    "data_threshold = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9n-uV6m5k5o"
   },
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:26:44.726234Z",
     "iopub.status.busy": "2022-09-04T06:26:44.725603Z",
     "iopub.status.idle": "2022-09-04T06:26:44.803443Z",
     "shell.execute_reply": "2022-09-04T06:26:44.802668Z",
     "shell.execute_reply.started": "2022-09-04T06:26:44.726205Z"
    },
    "id": "XAdEmY7J2YY1"
   },
   "outputs": [],
   "source": [
    "# y feature data의 threashold에 따른 정상 / 비정상 label 부여\n",
    "def get_label(data_df):\n",
    "  label = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    is_anomaly = False\n",
    "    for idx in range(len(data_threshold)):\n",
    "      if data_df[data_threshold[\"Feature\"].iloc[idx]].iloc[i] < data_threshold[\"최소\"].iloc[idx]:\n",
    "        is_anomaly = True\n",
    "        break\n",
    "      elif data_df[data_threshold[\"Feature\"].iloc[idx]].iloc[i] > data_threshold[\"최대\"].iloc[idx]:\n",
    "        is_anomaly = True\n",
    "        break\n",
    "    if is_anomaly:\n",
    "      label.append(1)\n",
    "    else:\n",
    "      label.append(0)\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:26:45.157756Z",
     "iopub.status.busy": "2022-09-04T06:26:45.157209Z",
     "iopub.status.idle": "2022-09-04T06:26:45.167239Z",
     "shell.execute_reply": "2022-09-04T06:26:45.166800Z",
     "shell.execute_reply.started": "2022-09-04T06:26:45.157734Z"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1660311399751,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "kBGUOzPG3Cv_",
    "outputId": "c8377ca4-3397-4253-9cbe-b50f3e82488b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>최소</th>\n",
       "      <th>최대</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y_01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y_02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y_03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y_04</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y_05</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature    최소    최대\n",
       "0    Y_01   0.2   2.0\n",
       "1    Y_02   0.2   2.1\n",
       "2    Y_03   0.2   2.1\n",
       "3    Y_04   7.0  19.0\n",
       "4    Y_05  22.0  36.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_threshold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:26:45.310853Z",
     "iopub.status.busy": "2022-09-04T06:26:45.310307Z",
     "iopub.status.idle": "2022-09-04T06:27:00.357270Z",
     "shell.execute_reply": "2022-09-04T06:27:00.356450Z",
     "shell.execute_reply.started": "2022-09-04T06:26:45.310830Z"
    },
    "id": "WrD1MNns4V2o"
   },
   "outputs": [],
   "source": [
    "data_train[\"label\"] = get_label(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.358920Z",
     "iopub.status.busy": "2022-09-04T06:27:00.358664Z",
     "iopub.status.idle": "2022-09-04T06:27:00.374883Z",
     "shell.execute_reply": "2022-09-04T06:27:00.374276Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.358895Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1660311430222,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "Y0D-no071ib_",
    "outputId": "d8b685cd-a0a0-4d6f-f50c-69a03ee6c052"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>70.544</td>\n",
       "      <td>103.320</td>\n",
       "      <td>67.47</td>\n",
       "      <td>1</td>\n",
       "      <td>101.892</td>\n",
       "      <td>74.983</td>\n",
       "      <td>29.45</td>\n",
       "      <td>62.38</td>\n",
       "      <td>245.71</td>\n",
       "      <td>...</td>\n",
       "      <td>16.083</td>\n",
       "      <td>4.276</td>\n",
       "      <td>-25.381</td>\n",
       "      <td>-25.529</td>\n",
       "      <td>-22.769</td>\n",
       "      <td>23.792</td>\n",
       "      <td>-25.470</td>\n",
       "      <td>-25.409</td>\n",
       "      <td>-25.304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>69.524</td>\n",
       "      <td>103.321</td>\n",
       "      <td>65.17</td>\n",
       "      <td>1</td>\n",
       "      <td>101.944</td>\n",
       "      <td>72.943</td>\n",
       "      <td>28.73</td>\n",
       "      <td>61.23</td>\n",
       "      <td>233.61</td>\n",
       "      <td>...</td>\n",
       "      <td>16.736</td>\n",
       "      <td>3.229</td>\n",
       "      <td>-26.619</td>\n",
       "      <td>-26.523</td>\n",
       "      <td>-22.574</td>\n",
       "      <td>24.691</td>\n",
       "      <td>-26.253</td>\n",
       "      <td>-26.497</td>\n",
       "      <td>-26.438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>72.583</td>\n",
       "      <td>103.320</td>\n",
       "      <td>64.07</td>\n",
       "      <td>1</td>\n",
       "      <td>103.153</td>\n",
       "      <td>72.943</td>\n",
       "      <td>28.81</td>\n",
       "      <td>105.77</td>\n",
       "      <td>272.20</td>\n",
       "      <td>...</td>\n",
       "      <td>17.080</td>\n",
       "      <td>2.839</td>\n",
       "      <td>-26.238</td>\n",
       "      <td>-26.216</td>\n",
       "      <td>-22.169</td>\n",
       "      <td>24.649</td>\n",
       "      <td>-26.285</td>\n",
       "      <td>-26.215</td>\n",
       "      <td>-26.370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>71.563</td>\n",
       "      <td>103.320</td>\n",
       "      <td>67.57</td>\n",
       "      <td>1</td>\n",
       "      <td>101.971</td>\n",
       "      <td>77.022</td>\n",
       "      <td>28.92</td>\n",
       "      <td>115.21</td>\n",
       "      <td>255.36</td>\n",
       "      <td>...</td>\n",
       "      <td>17.143</td>\n",
       "      <td>3.144</td>\n",
       "      <td>-25.426</td>\n",
       "      <td>-25.079</td>\n",
       "      <td>-21.765</td>\n",
       "      <td>24.913</td>\n",
       "      <td>-25.254</td>\n",
       "      <td>-25.021</td>\n",
       "      <td>-25.345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00005</td>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>63.57</td>\n",
       "      <td>1</td>\n",
       "      <td>101.981</td>\n",
       "      <td>70.904</td>\n",
       "      <td>29.68</td>\n",
       "      <td>103.38</td>\n",
       "      <td>241.46</td>\n",
       "      <td>...</td>\n",
       "      <td>17.569</td>\n",
       "      <td>3.138</td>\n",
       "      <td>-25.376</td>\n",
       "      <td>-25.242</td>\n",
       "      <td>-21.072</td>\n",
       "      <td>25.299</td>\n",
       "      <td>-25.072</td>\n",
       "      <td>-25.195</td>\n",
       "      <td>-24.974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08  \\\n",
       "0  TRAIN_00001  70.544  103.320  67.47     1  101.892  74.983  29.45   62.38   \n",
       "1  TRAIN_00002  69.524  103.321  65.17     1  101.944  72.943  28.73   61.23   \n",
       "2  TRAIN_00003  72.583  103.320  64.07     1  103.153  72.943  28.81  105.77   \n",
       "3  TRAIN_00004  71.563  103.320  67.57     1  101.971  77.022  28.92  115.21   \n",
       "4  TRAIN_00005  69.524  103.320  63.57     1  101.981  70.904  29.68  103.38   \n",
       "\n",
       "     X_09  ...    Y_06   Y_07    Y_08    Y_09    Y_10    Y_11    Y_12    Y_13  \\\n",
       "0  245.71  ...  16.083  4.276 -25.381 -25.529 -22.769  23.792 -25.470 -25.409   \n",
       "1  233.61  ...  16.736  3.229 -26.619 -26.523 -22.574  24.691 -26.253 -26.497   \n",
       "2  272.20  ...  17.080  2.839 -26.238 -26.216 -22.169  24.649 -26.285 -26.215   \n",
       "3  255.36  ...  17.143  3.144 -25.426 -25.079 -21.765  24.913 -25.254 -25.021   \n",
       "4  241.46  ...  17.569  3.138 -25.376 -25.242 -21.072  25.299 -25.072 -25.195   \n",
       "\n",
       "     Y_14  label  \n",
       "0 -25.304      1  \n",
       "1 -26.438      0  \n",
       "2 -26.370      0  \n",
       "3 -25.345      0  \n",
       "4 -24.974      0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.375701Z",
     "iopub.status.busy": "2022-09-04T06:27:00.375543Z",
     "iopub.status.idle": "2022-09-04T06:27:00.388164Z",
     "shell.execute_reply": "2022-09-04T06:27:00.387667Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.375687Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1660311430223,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "c38sdCY-1mtj",
    "outputId": "6fbd7aa5-ac55-4742-856b-ba192ea24200"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X_01</th>\n",
       "      <th>X_02</th>\n",
       "      <th>X_03</th>\n",
       "      <th>X_04</th>\n",
       "      <th>X_05</th>\n",
       "      <th>X_06</th>\n",
       "      <th>X_07</th>\n",
       "      <th>X_08</th>\n",
       "      <th>X_09</th>\n",
       "      <th>...</th>\n",
       "      <th>X_47</th>\n",
       "      <th>X_48</th>\n",
       "      <th>X_49</th>\n",
       "      <th>X_50</th>\n",
       "      <th>X_51</th>\n",
       "      <th>X_52</th>\n",
       "      <th>X_53</th>\n",
       "      <th>X_54</th>\n",
       "      <th>X_55</th>\n",
       "      <th>X_56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>68.504</td>\n",
       "      <td>103.321</td>\n",
       "      <td>76.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.867</td>\n",
       "      <td>73.963</td>\n",
       "      <td>30.51</td>\n",
       "      <td>63.57</td>\n",
       "      <td>239.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17227.63</td>\n",
       "      <td>138.130429</td>\n",
       "      <td>129.460682</td>\n",
       "      <td>141.506570</td>\n",
       "      <td>133.427229</td>\n",
       "      <td>129.711498</td>\n",
       "      <td>133.138096</td>\n",
       "      <td>121.859684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>67.485</td>\n",
       "      <td>103.320</td>\n",
       "      <td>69.37</td>\n",
       "      <td>1</td>\n",
       "      <td>101.992</td>\n",
       "      <td>67.845</td>\n",
       "      <td>28.03</td>\n",
       "      <td>116.99</td>\n",
       "      <td>189.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17134.53</td>\n",
       "      <td>136.148839</td>\n",
       "      <td>128.266277</td>\n",
       "      <td>145.911745</td>\n",
       "      <td>131.196417</td>\n",
       "      <td>132.411480</td>\n",
       "      <td>133.629025</td>\n",
       "      <td>124.178623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>68.97</td>\n",
       "      <td>1</td>\n",
       "      <td>101.884</td>\n",
       "      <td>77.022</td>\n",
       "      <td>29.65</td>\n",
       "      <td>205.68</td>\n",
       "      <td>214.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14860.83</td>\n",
       "      <td>120.447446</td>\n",
       "      <td>119.988804</td>\n",
       "      <td>132.099908</td>\n",
       "      <td>120.450155</td>\n",
       "      <td>130.051708</td>\n",
       "      <td>128.252972</td>\n",
       "      <td>114.475628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>69.524</td>\n",
       "      <td>103.320</td>\n",
       "      <td>65.87</td>\n",
       "      <td>1</td>\n",
       "      <td>101.866</td>\n",
       "      <td>73.963</td>\n",
       "      <td>28.15</td>\n",
       "      <td>103.38</td>\n",
       "      <td>180.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15252.53</td>\n",
       "      <td>133.994695</td>\n",
       "      <td>125.069180</td>\n",
       "      <td>147.507669</td>\n",
       "      <td>123.142653</td>\n",
       "      <td>125.963665</td>\n",
       "      <td>139.666592</td>\n",
       "      <td>126.589253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00005</td>\n",
       "      <td>73.603</td>\n",
       "      <td>103.321</td>\n",
       "      <td>66.67</td>\n",
       "      <td>1</td>\n",
       "      <td>101.891</td>\n",
       "      <td>74.983</td>\n",
       "      <td>29.92</td>\n",
       "      <td>71.20</td>\n",
       "      <td>231.93</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10752.23</td>\n",
       "      <td>137.918202</td>\n",
       "      <td>135.116192</td>\n",
       "      <td>138.600473</td>\n",
       "      <td>127.173033</td>\n",
       "      <td>137.252712</td>\n",
       "      <td>134.411335</td>\n",
       "      <td>124.020016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    X_01     X_02   X_03  X_04     X_05    X_06   X_07    X_08  \\\n",
       "0  TEST_00001  68.504  103.321  76.67     1  101.867  73.963  30.51   63.57   \n",
       "1  TEST_00002  67.485  103.320  69.37     1  101.992  67.845  28.03  116.99   \n",
       "2  TEST_00003  69.524  103.320  68.97     1  101.884  77.022  29.65  205.68   \n",
       "3  TEST_00004  69.524  103.320  65.87     1  101.866  73.963  28.15  103.38   \n",
       "4  TEST_00005  73.603  103.321  66.67     1  101.891  74.983  29.92   71.20   \n",
       "\n",
       "     X_09  ...  X_47  X_48      X_49        X_50        X_51        X_52  \\\n",
       "0  239.80  ...     1     1  17227.63  138.130429  129.460682  141.506570   \n",
       "1  189.23  ...     1     1  17134.53  136.148839  128.266277  145.911745   \n",
       "2  214.93  ...     1     1  14860.83  120.447446  119.988804  132.099908   \n",
       "3  180.80  ...     1     1  15252.53  133.994695  125.069180  147.507669   \n",
       "4  231.93  ...     1     1  10752.23  137.918202  135.116192  138.600473   \n",
       "\n",
       "         X_53        X_54        X_55        X_56  \n",
       "0  133.427229  129.711498  133.138096  121.859684  \n",
       "1  131.196417  132.411480  133.629025  124.178623  \n",
       "2  120.450155  130.051708  128.252972  114.475628  \n",
       "3  123.142653  125.963665  139.666592  126.589253  \n",
       "4  127.173033  137.252712  134.411335  124.020016  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDjltRHSQanX"
   },
   "source": [
    "### 데이터 target 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.389528Z",
     "iopub.status.busy": "2022-09-04T06:27:00.389368Z",
     "iopub.status.idle": "2022-09-04T06:27:00.636942Z",
     "shell.execute_reply": "2022-09-04T06:27:00.636419Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.389515Z"
    },
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1660311431322,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "Uvd6dbGKN0cr",
    "outputId": "9c0c1cde-838f-4d5f-fa79-cbe55b077a69"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = [0, 0]\n",
    "\n",
    "for i in range(data_train.shape[0]):\n",
    "\n",
    "    if data_train[\"label\"].iloc[i] == 0:\n",
    "        result[0] += 1\n",
    "    else:\n",
    "        result[1] += 1 \n",
    "            \n",
    "labels = [\"non-anomaly\", \"anomaly\"]\n",
    "result = np.array(result)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8)) ## 캔버스 생성\n",
    "fig.set_facecolor('white') ## 캔버스 색상 하얀색\n",
    " \n",
    "ax = fig.add_subplot() ## 프레임 생성\n",
    " \n",
    "ax.pie(x=result,labels=labels,autopct=lambda p : '{:.2f}%'.format(p)) ## 파이 차트 출력\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1X7L8C7BWxr"
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.637777Z",
     "iopub.status.busy": "2022-09-04T06:27:00.637613Z",
     "iopub.status.idle": "2022-09-04T06:27:00.663571Z",
     "shell.execute_reply": "2022-09-04T06:27:00.662960Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.637762Z"
    },
    "id": "tKO_Zv1O9uJl"
   },
   "outputs": [],
   "source": [
    "X_drop_list = ['ID', \"label\"]\n",
    "for i in range(1, 15):\n",
    "  i = str(i)\n",
    "  if len(i) == 1:\n",
    "    i = '0'+i\n",
    "  X_drop_list.append(\"Y_\"+i)\n",
    "\n",
    "Y_drop_list = ['ID']\n",
    "for i in range(1, 57):\n",
    "  i = str(i)\n",
    "  if len(i) == 1:\n",
    "    i = '0'+i\n",
    "  Y_drop_list.append(\"X_\"+i)\n",
    "\n",
    "data_train_X = data_train.drop(X_drop_list, axis = 1)\n",
    "data_train_y = data_train.drop(Y_drop_list, axis = 1)\n",
    "data_test = data_test.drop([\"ID\"], axis = 1)\n",
    "\n",
    "# 추가 필요없는 x feature drop\n",
    "drop_list = [\"X_04\", \"X_23\", \"X_47\", \"X_48\"]\n",
    "data_train_X = data_train_X.drop(drop_list, axis = 1)\n",
    "data_test = data_test.drop(drop_list, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuD60l6ZcB0Y"
   },
   "source": [
    "### 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.664796Z",
     "iopub.status.busy": "2022-09-04T06:27:00.664358Z",
     "iopub.status.idle": "2022-09-04T06:27:00.668468Z",
     "shell.execute_reply": "2022-09-04T06:27:00.667911Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.664780Z"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1660311437378,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "cDi2ZMhqc33z",
    "outputId": "65bffe3f-0cda-4449-80b7-da346a19a07f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
       "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
       "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
       "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
       "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
       "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.669230Z",
     "iopub.status.busy": "2022-09-04T06:27:00.669084Z",
     "iopub.status.idle": "2022-09-04T06:27:00.673504Z",
     "shell.execute_reply": "2022-09-04T06:27:00.672915Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.669216Z"
    },
    "id": "ncm6LX_Pd4Tg"
   },
   "outputs": [],
   "source": [
    "def get_values(data_df, start_val, end_val, get_std = False):\n",
    "  diff = []\n",
    "  std = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    vals = []\n",
    "    for s in range(start_val, end_val + 1):\n",
    "      vals.append(data_df[\"X_\"+str(s)].iloc[i])\n",
    "    diff.append(max(vals) - min(vals))\n",
    "    if get_std:\n",
    "      std.append(np.std(vals))\n",
    "  return diff, std\n",
    "\n",
    "def get_sum_values(data_df, val_list):\n",
    "  sums = []\n",
    "  for i in range(data_df.shape[0]):\n",
    "    vals = []\n",
    "    for s in val_list:\n",
    "      vals.append(data_df[\"X_\"+str(s)].iloc[i])\n",
    "    sums.append(sum(vals))\n",
    "  return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:00.674242Z",
     "iopub.status.busy": "2022-09-04T06:27:00.674098Z",
     "iopub.status.idle": "2022-09-04T06:27:05.343191Z",
     "shell.execute_reply": "2022-09-04T06:27:05.342623Z",
     "shell.execute_reply.started": "2022-09-04T06:27:00.674230Z"
    },
    "id": "oRwVE1-ZsGNy"
   },
   "outputs": [],
   "source": [
    "\n",
    "### 무게 / 면적\n",
    "data_train_X[\"X_03/X_07\"] = data_train_X[\"X_03\"] / data_train_X[\"X_07\"]\n",
    "data_test[\"X_03/X_07\"] = data_test[\"X_03\"] / data_test[\"X_07\"]\n",
    "\n",
    "### 레이돔 치수 차이 ###\n",
    "diff, std = get_values(data_train_X, 41, 44)\n",
    "data_train_X[\"X_41~44-diff\"] = diff\n",
    "diff, std = get_values(data_test, 41, 44)\n",
    "data_test[\"X_41~44-diff\"] = diff\n",
    "\n",
    "### 1~4 단계별 누름량 합산 ###\n",
    "sums = get_sum_values(data_train_X, [\"01\", \"02\", \"05\", \"06\"])\n",
    "data_train_X[\"X_1~6_push-sum\"] = sums\n",
    "sums = get_sum_values(data_test, [\"01\", \"02\", \"05\", \"06\"])\n",
    "data_test[\"X_1~6_push-sum\"] = sums\n",
    "\n",
    "### 방열 재료 면적 합산 ###\n",
    "sums = get_sum_values(data_train_X, [\"07\", \"08\", \"09\"])\n",
    "data_train_X[\"X_7~9_area-sum\"] = sums\n",
    "sums = get_sum_values(data_test, [\"07\", \"08\", \"09\"])\n",
    "data_test[\"X_7~9_area-sum\"] = sums\n",
    "\n",
    "### 스크류 삽입 깊이가 재질과 관련?\n",
    "data_train_X[\"X_03/X_19~22\"] = data_train_X[\"X_03\"]/(data_train_X[\"X_19\"]+data_train_X[\"X_20\"]+data_train_X[\"X_21\"]+data_train_X[\"X_22\"])\n",
    "data_test[\"X_03/X_19~22\"] = data_test[\"X_03\"]/(data_test[\"X_19\"]+data_test[\"X_20\"]+data_test[\"X_21\"]+data_test[\"X_22\"])\n",
    "\n",
    "# 커넥터 위치 좌표와 커넥터핀 치수 관계\n",
    "data_train_X[\"X_12/X_24~25\"] = data_train_X[\"X_12\"] / ((data_train_X[\"X_24\"]+data_train_X[\"X_25\"])/2)\n",
    "data_test[\"X_12/X_24~25\"] = data_test[\"X_12\"] / ((data_test[\"X_24\"]+data_test[\"X_25\"])/2)\n",
    "\n",
    "#importance 높은 데이터 조합\n",
    "data_train_X[\"49_7_19_3_8\"] = data_train_X[\"X_49\"] / data_train_X[\"X_49\"].mean()+data_train_X[\"X_07\"] / data_train_X[\"X_07\"].mean()+data_train_X[\"X_19\"] / data_train_X[\"X_19\"].mean()+data_train_X[\"X_03\"] / data_train_X[\"X_03\"].mean()\n",
    "data_test[\"49_7_19_3_8\"] = data_test[\"X_49\"] / data_train_X[\"X_49\"].mean()+data_test[\"X_07\"] / data_train_X[\"X_07\"].mean()+data_test[\"X_19\"] / data_train_X[\"X_19\"].mean()+data_test[\"X_03\"] / data_train_X[\"X_03\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:05.344075Z",
     "iopub.status.busy": "2022-09-04T06:27:05.343915Z",
     "iopub.status.idle": "2022-09-04T06:27:05.354847Z",
     "shell.execute_reply": "2022-09-04T06:27:05.354261Z",
     "shell.execute_reply.started": "2022-09-04T06:27:05.344061Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1660311613151,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "ukVsfbX1-soo",
    "outputId": "fc1472d1-54df-4037-c56e-c66935081667"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.056</td>\n",
       "      <td>1.456</td>\n",
       "      <td>1.680</td>\n",
       "      <td>10.502</td>\n",
       "      <td>29.632</td>\n",
       "      <td>16.083</td>\n",
       "      <td>4.276</td>\n",
       "      <td>-25.381</td>\n",
       "      <td>-25.529</td>\n",
       "      <td>-22.769</td>\n",
       "      <td>23.792</td>\n",
       "      <td>-25.470</td>\n",
       "      <td>-25.409</td>\n",
       "      <td>-25.304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.446</td>\n",
       "      <td>1.184</td>\n",
       "      <td>1.268</td>\n",
       "      <td>18.507</td>\n",
       "      <td>33.179</td>\n",
       "      <td>16.736</td>\n",
       "      <td>3.229</td>\n",
       "      <td>-26.619</td>\n",
       "      <td>-26.523</td>\n",
       "      <td>-22.574</td>\n",
       "      <td>24.691</td>\n",
       "      <td>-26.253</td>\n",
       "      <td>-26.497</td>\n",
       "      <td>-26.438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.251</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.782</td>\n",
       "      <td>14.082</td>\n",
       "      <td>31.801</td>\n",
       "      <td>17.080</td>\n",
       "      <td>2.839</td>\n",
       "      <td>-26.238</td>\n",
       "      <td>-26.216</td>\n",
       "      <td>-22.169</td>\n",
       "      <td>24.649</td>\n",
       "      <td>-26.285</td>\n",
       "      <td>-26.215</td>\n",
       "      <td>-26.370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.464</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.052</td>\n",
       "      <td>16.975</td>\n",
       "      <td>34.503</td>\n",
       "      <td>17.143</td>\n",
       "      <td>3.144</td>\n",
       "      <td>-25.426</td>\n",
       "      <td>-25.079</td>\n",
       "      <td>-21.765</td>\n",
       "      <td>24.913</td>\n",
       "      <td>-25.254</td>\n",
       "      <td>-25.021</td>\n",
       "      <td>-25.345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.689</td>\n",
       "      <td>15.047</td>\n",
       "      <td>32.602</td>\n",
       "      <td>17.569</td>\n",
       "      <td>3.138</td>\n",
       "      <td>-25.376</td>\n",
       "      <td>-25.242</td>\n",
       "      <td>-21.072</td>\n",
       "      <td>25.299</td>\n",
       "      <td>-25.072</td>\n",
       "      <td>-25.195</td>\n",
       "      <td>-24.974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_01   Y_02   Y_03    Y_04    Y_05    Y_06   Y_07    Y_08    Y_09    Y_10  \\\n",
       "0  2.056  1.456  1.680  10.502  29.632  16.083  4.276 -25.381 -25.529 -22.769   \n",
       "1  1.446  1.184  1.268  18.507  33.179  16.736  3.229 -26.619 -26.523 -22.574   \n",
       "2  1.251  0.665  0.782  14.082  31.801  17.080  2.839 -26.238 -26.216 -22.169   \n",
       "3  1.464  1.079  1.052  16.975  34.503  17.143  3.144 -25.426 -25.079 -21.765   \n",
       "4  0.983  0.646  0.689  15.047  32.602  17.569  3.138 -25.376 -25.242 -21.072   \n",
       "\n",
       "     Y_11    Y_12    Y_13    Y_14  label  \n",
       "0  23.792 -25.470 -25.409 -25.304      1  \n",
       "1  24.691 -26.253 -26.497 -26.438      0  \n",
       "2  24.649 -26.285 -26.215 -26.370      0  \n",
       "3  24.913 -25.254 -25.021 -25.345      0  \n",
       "4  25.299 -25.072 -25.195 -24.974      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBQV42MXPAeW"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpFjUI21Uxoo"
   },
   "source": [
    "### nrmse score metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:05.356631Z",
     "iopub.status.busy": "2022-09-04T06:27:05.356468Z",
     "iopub.status.idle": "2022-09-04T06:27:06.819752Z",
     "shell.execute_reply": "2022-09-04T06:27:06.819115Z",
     "shell.execute_reply.started": "2022-09-04T06:27:05.356618Z"
    },
    "id": "9PPX1B7XUsDk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def lg_nrmse(gt, preds):\n",
    "    # 각 Y Feature별 NRMSE 총합\n",
    "    # Y_01 ~ Y_08 까지 20% 가중치 부여\n",
    "    all_nrmse = []\n",
    "    for idx in range(14): # ignore 'ID'\n",
    "        rmse = mean_squared_error(gt[:,idx], preds[:,idx], squared=False)\n",
    "        nrmse = rmse/np.mean(np.abs(gt[:,idx]))\n",
    "        all_nrmse.append(nrmse)\n",
    "    score = 1.2 * np.sum(all_nrmse[:7]) + 1.0 * np.sum(all_nrmse[7:14])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfnxFD3AbJMH"
   },
   "source": [
    "### Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:06.820905Z",
     "iopub.status.busy": "2022-09-04T06:27:06.820560Z",
     "iopub.status.idle": "2022-09-04T06:27:08.859882Z",
     "shell.execute_reply": "2022-09-04T06:27:08.859014Z",
     "shell.execute_reply.started": "2022-09-04T06:27:06.820889Z"
    },
    "executionInfo": {
     "elapsed": 11671,
     "status": "ok",
     "timestamp": 1660311628504,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "MQnxW4cDYX5G",
    "outputId": "8a70af92-e298-48a1-9a4b-476732e1a92d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /usr/local/lib/python3.9/dist-packages (1.0.6)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.8.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.23.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.34.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:08.861236Z",
     "iopub.status.busy": "2022-09-04T06:27:08.861021Z",
     "iopub.status.idle": "2022-09-04T06:27:10.890272Z",
     "shell.execute_reply": "2022-09-04T06:27:10.889505Z",
     "shell.execute_reply.started": "2022-09-04T06:27:08.861216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm==2.2.3 in /usr/local/lib/python3.9/dist-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from lightgbm==2.2.3) (1.1.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lightgbm==2.2.3) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lightgbm==2.2.3) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->lightgbm==2.2.3) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->lightgbm==2.2.3) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:10.892157Z",
     "iopub.status.busy": "2022-09-04T06:27:10.891502Z",
     "iopub.status.idle": "2022-09-04T06:27:13.332462Z",
     "shell.execute_reply": "2022-09-04T06:27:13.331596Z",
     "shell.execute_reply.started": "2022-09-04T06:27:10.892126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.9/dist-packages (0.90)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost==0.90) (1.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost==0.90) (1.23.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom multiouputRegressor\n",
    "for use early stopping & model save, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:13.333917Z",
     "iopub.status.busy": "2022-09-04T06:27:13.333699Z",
     "iopub.status.idle": "2022-09-04T06:27:13.361773Z",
     "shell.execute_reply": "2022-09-04T06:27:13.361105Z",
     "shell.execute_reply.started": "2022-09-04T06:27:13.333897Z"
    },
    "id": "hRu-D4lBrT5-"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils.fixes import delayed\n",
    "from joblib import Parallel\n",
    "from sklearn.multioutput import _fit_estimator\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm\n",
    "\n",
    "class MyMultiOutputRegressor_LGBM(MultiOutputRegressor):\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, **fit_params):\n",
    "        \"\"\" Fit the model to data.\n",
    "        Fit a separate model for each output variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            Multi-output targets. An indicator matrix turns on multilabel\n",
    "            estimation.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Only supported if the underlying regressor supports sample\n",
    "            weights.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``estimator.fit`` method of each step.\n",
    "            .. versionadded:: 0.23\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.estimator, \"fit\"):\n",
    "            raise ValueError(\"The base estimator should implement\"\n",
    "                             \" a fit method\")\n",
    "\n",
    "        X, y = self._validate_data(X, y,\n",
    "                                   force_all_finite=False,\n",
    "                                   multi_output=True, accept_sparse=True)\n",
    "\n",
    "        if is_classifier(self):\n",
    "            check_classification_targets(y)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            raise ValueError(\"y must have at least two dimensions for \"\n",
    "                             \"multi-output regression but has only one.\")\n",
    "\n",
    "        if (sample_weight is not None and\n",
    "                not has_fit_parameter(self.estimator, 'sample_weight')):\n",
    "            raise ValueError(\"Underlying estimator does not support\"\n",
    "                             \" sample weights.\")\n",
    "            \n",
    "        lambda_y = lambda i: '0'+str(i+1) if i<9 else str(i+1)\n",
    "\n",
    "        fit_params_validated = _check_fit_params(X, fit_params)\n",
    "        [(X_test, Y_test)] = fit_params_validated.pop('eval_set')\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_estimator)(\n",
    "                self.estimator, X, y[:, i], sample_weight,\n",
    "                **fit_params_validated, \n",
    "                eval_set=[(X_test, Y_test[:, i])], \n",
    "                eval_names=\"Y_\" + lambda_y(i),\n",
    "                verbose=-1, \n",
    "                callbacks=[lightgbm.early_stopping(200)])\n",
    "            for i in range(y.shape[1]))\n",
    "        return self\n",
    "    \n",
    "    # model save\n",
    "    def save(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.txt'.format(path, chain_idx)\n",
    "            estimator.booster_.save_model(save_path)\n",
    "    \n",
    "    # model load\n",
    "    def load(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.txt'.format(path, chain_idx)\n",
    "            self.estimators_[chain_idx] = lightgbm.Booster(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:13.362757Z",
     "iopub.status.busy": "2022-09-04T06:27:13.362592Z",
     "iopub.status.idle": "2022-09-04T06:27:13.376265Z",
     "shell.execute_reply": "2022-09-04T06:27:13.375786Z",
     "shell.execute_reply.started": "2022-09-04T06:27:13.362746Z"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1660322335263,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "OYQUGtFa7Gs8"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import _check_fit_params\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils.fixes import delayed\n",
    "from joblib import Parallel\n",
    "from sklearn.multioutput import _fit_estimator\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "class MyMultiOutputRegressor_XGB(MultiOutputRegressor):\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None, **fit_params):\n",
    "        \"\"\" Fit the model to data.\n",
    "        Fit a separate model for each output variable.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "            Data.\n",
    "        y : {array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            Multi-output targets. An indicator matrix turns on multilabel\n",
    "            estimation.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Sample weights. If None, then samples are equally weighted.\n",
    "            Only supported if the underlying regressor supports sample\n",
    "            weights.\n",
    "        **fit_params : dict of string -> object\n",
    "            Parameters passed to the ``estimator.fit`` method of each step.\n",
    "            .. versionadded:: 0.23\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self.estimator, \"fit\"):\n",
    "            raise ValueError(\"The base estimator should implement\"\n",
    "                             \" a fit method\")\n",
    "\n",
    "        X, y = self._validate_data(X, y,\n",
    "                                   force_all_finite=False,\n",
    "                                   multi_output=True, accept_sparse=True)\n",
    "\n",
    "        if is_classifier(self):\n",
    "            check_classification_targets(y)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            raise ValueError(\"y must have at least two dimensions for \"\n",
    "                             \"multi-output regression but has only one.\")\n",
    "\n",
    "        if (sample_weight is not None and\n",
    "                not has_fit_parameter(self.estimator, 'sample_weight')):\n",
    "            raise ValueError(\"Underlying estimator does not support\"\n",
    "                             \" sample weights.\")\n",
    "\n",
    "        fit_params_validated = _check_fit_params(X, fit_params)\n",
    "        [(X_test, Y_test)] = fit_params_validated.pop('eval_set')\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_estimator)(\n",
    "                self.estimator, X, y[:, i],\n",
    "                eval_set=[(X_test, Y_test[:, i])],\n",
    "                early_stopping_rounds=100, \n",
    "                #eval_metric = [\"rmse\"], \n",
    "                verbose=3000)\n",
    "            \n",
    "            for i in range(y.shape[1]))\n",
    "        return self\n",
    "    \n",
    "    # model save\n",
    "    def save(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.dat'.format(path, chain_idx)\n",
    "            pickle.dump(estimator, open(save_path, \"wb\"))\n",
    "    \n",
    "    # model load\n",
    "    def load(self, path):\n",
    "        for chain_idx, estimator in enumerate(self.estimators_):\n",
    "            save_path = '{}_{}.dat'.format(path, chain_idx)\n",
    "            model = pickle.load(open(save_path, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "861BoI4q7SgE"
   },
   "source": [
    "# 모델 학습\n",
    "(CAT + XGB + LGB) with 6 CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T06:27:13.377209Z",
     "iopub.status.busy": "2022-09-04T06:27:13.377042Z",
     "iopub.status.idle": "2022-09-04T08:36:50.379550Z",
     "shell.execute_reply": "2022-09-04T08:36:50.378869Z",
     "shell.execute_reply.started": "2022-09-04T06:27:13.377193Z"
    },
    "executionInfo": {
     "elapsed": 4776458,
     "status": "ok",
     "timestamp": 1660337547982,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "-WO84oeTsGN0",
    "outputId": "5f8cc886-a9d5-4c86-cddb-2d337673e40e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.6352787\ttest: 4.6553672\tbest: 4.6553672 (0)\ttotal: 227ms\tremaining: 18m 54s\n",
      "200:\tlearn: 4.3642074\ttest: 4.5361587\tbest: 4.5361587 (200)\ttotal: 35.7s\tremaining: 14m 12s\n",
      "400:\tlearn: 4.2296767\ttest: 4.5122390\tbest: 4.5122182 (399)\ttotal: 1m 10s\tremaining: 13m 25s\n",
      "600:\tlearn: 4.1193230\ttest: 4.4969338\tbest: 4.4969338 (600)\ttotal: 1m 44s\tremaining: 12m 47s\n",
      "800:\tlearn: 4.0108089\ttest: 4.4846937\tbest: 4.4846622 (798)\ttotal: 2m 18s\tremaining: 12m 7s\n",
      "1000:\tlearn: 3.9048064\ttest: 4.4747544\tbest: 4.4747025 (988)\ttotal: 2m 53s\tremaining: 11m 32s\n",
      "1200:\tlearn: 3.8093561\ttest: 4.4687731\tbest: 4.4687731 (1200)\ttotal: 3m 27s\tremaining: 10m 57s\n",
      "1400:\tlearn: 3.7193387\ttest: 4.4639210\tbest: 4.4637640 (1397)\ttotal: 4m 2s\tremaining: 10m 21s\n",
      "1600:\tlearn: 3.6299716\ttest: 4.4606051\tbest: 4.4606001 (1593)\ttotal: 4m 36s\tremaining: 9m 47s\n",
      "1800:\tlearn: 3.5433574\ttest: 4.4583479\tbest: 4.4582837 (1791)\ttotal: 5m 11s\tremaining: 9m 13s\n",
      "2000:\tlearn: 3.4615257\ttest: 4.4561844\tbest: 4.4559083 (1985)\ttotal: 5m 46s\tremaining: 8m 39s\n",
      "2200:\tlearn: 3.3783542\ttest: 4.4537485\tbest: 4.4537485 (2200)\ttotal: 6m 21s\tremaining: 8m 4s\n",
      "2400:\tlearn: 3.2916031\ttest: 4.4515920\tbest: 4.4512213 (2385)\ttotal: 6m 56s\tremaining: 7m 30s\n",
      "2600:\tlearn: 3.2117426\ttest: 4.4507857\tbest: 4.4506674 (2552)\ttotal: 7m 30s\tremaining: 6m 55s\n",
      "2800:\tlearn: 3.1331144\ttest: 4.4506752\tbest: 4.4503170 (2661)\ttotal: 8m 5s\tremaining: 6m 20s\n",
      "3000:\tlearn: 3.0581472\ttest: 4.4497504\tbest: 4.4496783 (2998)\ttotal: 8m 39s\tremaining: 5m 46s\n",
      "3200:\tlearn: 2.9839712\ttest: 4.4495029\tbest: 4.4495029 (3200)\ttotal: 9m 14s\tremaining: 5m 11s\n",
      "3400:\tlearn: 2.9108088\ttest: 4.4490207\tbest: 4.4485784 (3334)\ttotal: 9m 48s\tremaining: 4m 36s\n",
      "3600:\tlearn: 2.8367010\ttest: 4.4481523\tbest: 4.4480286 (3581)\ttotal: 10m 23s\tremaining: 4m 2s\n",
      "3800:\tlearn: 2.7674972\ttest: 4.4483135\tbest: 4.4477281 (3628)\ttotal: 10m 58s\tremaining: 3m 27s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.447728132\n",
      "bestIteration = 3628\n",
      "\n",
      "Shrink model to first 3629 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[336]\tY_01's rmse: 0.349251\tY_01's l2: 0.121976\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[261]\tY_02's rmse: 0.373977\tY_02's l2: 0.139859\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[340]\tY_03's rmse: 0.353271\tY_03's l2: 0.1248\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1195]\tY_04's rmse: 2.52051\tY_04's l2: 6.35296\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[614]\tY_05's rmse: 2.49697\tY_05's l2: 6.23487\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[977]\tY_06's rmse: 1.77572\tY_06's l2: 3.15317\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[636]\tY_07's rmse: 0.406155\tY_07's l2: 0.164962\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[524]\tY_08's rmse: 0.629786\tY_08's l2: 0.39663\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[763]\tY_09's rmse: 0.625452\tY_09's l2: 0.39119\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[816]\tY_10's rmse: 0.854311\tY_10's l2: 0.729847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[793]\tY_11's rmse: 0.811037\tY_11's l2: 0.65778\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[494]\tY_12's rmse: 0.63011\tY_12's l2: 0.397039\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[425]\tY_13's rmse: 0.624863\tY_13's l2: 0.390454\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[535]\tY_14's rmse: 0.628421\tY_14's l2: 0.394912\n",
      "[0]\tvalidation_0-rmse:0.923838\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[961]\tvalidation_0-rmse:0.34891\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.676095\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1124]\tvalidation_0-rmse:0.373348\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.62812\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[808]\tvalidation_0-rmse:0.352751\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.3453\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2824]\tvalidation_0-rmse:2.51424\n",
      "\n",
      "[0]\tvalidation_0-rmse:30.7294\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1771]\tvalidation_0-rmse:2.49218\n",
      "\n",
      "[0]\tvalidation_0-rmse:16.0474\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1503]\tvalidation_0-rmse:1.80527\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.67245\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2047]\tvalidation_0-rmse:0.405501\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6301\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2306]\tvalidation_0-rmse:0.630262\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6436\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2139]\tvalidation_0-rmse:0.625696\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7719\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2158]\tvalidation_0-rmse:0.852108\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.6987\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2674]\tvalidation_0-rmse:0.808441\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.572\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1952]\tvalidation_0-rmse:0.630068\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5679\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1480]\tvalidation_0-rmse:0.625322\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5795\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2068]\tvalidation_0-rmse:0.627938\n",
      "\n",
      "========== fold 1 ==========\n",
      "CatBoostRegressor model nrmse : 1.9418\n",
      "LGBMRegressor model nrmse : 1.9402\n",
      "XGBRegressor model nrmse : 1.9395\n",
      "CAT 코드 실행 시간:        719s\n",
      "LGB 코드 실행 시간:        118s\n",
      "XGB 코드 실행 시간:        414s\n",
      "average model nrmse : 1.9351\n",
      "0:\tlearn: 4.6394568\ttest: 4.6313296\tbest: 4.6313296 (0)\ttotal: 172ms\tremaining: 14m 21s\n",
      "200:\tlearn: 4.3666765\ttest: 4.4982676\tbest: 4.4982676 (200)\ttotal: 34.8s\tremaining: 13m 51s\n",
      "400:\tlearn: 4.2262821\ttest: 4.4672197\tbest: 4.4672127 (399)\ttotal: 1m 9s\tremaining: 13m 15s\n",
      "600:\tlearn: 4.1125763\ttest: 4.4476730\tbest: 4.4476730 (600)\ttotal: 1m 43s\tremaining: 12m 37s\n",
      "800:\tlearn: 4.0010080\ttest: 4.4318269\tbest: 4.4318269 (800)\ttotal: 2m 17s\tremaining: 12m 3s\n",
      "1000:\tlearn: 3.9037419\ttest: 4.4234590\tbest: 4.4234336 (999)\ttotal: 2m 52s\tremaining: 11m 28s\n",
      "1200:\tlearn: 3.8097918\ttest: 4.4146125\tbest: 4.4145928 (1199)\ttotal: 3m 26s\tremaining: 10m 53s\n",
      "1400:\tlearn: 3.7239502\ttest: 4.4088021\tbest: 4.4087916 (1398)\ttotal: 4m 1s\tremaining: 10m 19s\n",
      "1600:\tlearn: 3.6382474\ttest: 4.4044854\tbest: 4.4044854 (1600)\ttotal: 4m 35s\tremaining: 9m 44s\n",
      "1800:\tlearn: 3.5529527\ttest: 4.4000244\tbest: 4.3999410 (1798)\ttotal: 5m 10s\tremaining: 9m 10s\n",
      "2000:\tlearn: 3.4702355\ttest: 4.3972488\tbest: 4.3972177 (1999)\ttotal: 5m 43s\tremaining: 8m 35s\n",
      "2200:\tlearn: 3.3875123\ttest: 4.3950557\tbest: 4.3947533 (2179)\ttotal: 6m 17s\tremaining: 8m\n",
      "2400:\tlearn: 3.3039682\ttest: 4.3918939\tbest: 4.3918717 (2399)\ttotal: 6m 52s\tremaining: 7m 26s\n",
      "2600:\tlearn: 3.2230774\ttest: 4.3880481\tbest: 4.3880308 (2599)\ttotal: 7m 27s\tremaining: 6m 52s\n",
      "2800:\tlearn: 3.1440765\ttest: 4.3861505\tbest: 4.3861283 (2798)\ttotal: 8m 2s\tremaining: 6m 18s\n",
      "3000:\tlearn: 3.0707365\ttest: 4.3846555\tbest: 4.3846360 (2997)\ttotal: 8m 37s\tremaining: 5m 44s\n",
      "3200:\tlearn: 2.9954158\ttest: 4.3837650\tbest: 4.3837650 (3200)\ttotal: 9m 11s\tremaining: 5m 9s\n",
      "3400:\tlearn: 2.9240759\ttest: 4.3834813\tbest: 4.3834772 (3399)\ttotal: 9m 46s\tremaining: 4m 35s\n",
      "3600:\tlearn: 2.8507285\ttest: 4.3831928\tbest: 4.3828613 (3508)\ttotal: 10m 20s\tremaining: 4m 1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.382861316\n",
      "bestIteration = 3508\n",
      "\n",
      "Shrink model to first 3509 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[278]\tY_01's rmse: 0.349233\tY_01's l2: 0.121964\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[452]\tY_02's rmse: 0.37914\tY_02's l2: 0.143747\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[339]\tY_03's rmse: 0.358442\tY_03's l2: 0.128481\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[883]\tY_04's rmse: 2.56405\tY_04's l2: 6.57435\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1165]\tY_05's rmse: 2.51862\tY_05's l2: 6.34342\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1118]\tY_06's rmse: 1.55754\tY_06's l2: 2.42592\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[951]\tY_07's rmse: 0.399049\tY_07's l2: 0.15924\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[808]\tY_08's rmse: 0.630068\tY_08's l2: 0.396985\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[602]\tY_09's rmse: 0.625148\tY_09's l2: 0.39081\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[948]\tY_10's rmse: 0.839282\tY_10's l2: 0.704394\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1224]\tY_11's rmse: 0.804397\tY_11's l2: 0.647055\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[830]\tY_12's rmse: 0.62582\tY_12's l2: 0.391651\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[612]\tY_13's rmse: 0.626892\tY_13's l2: 0.392993\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[720]\tY_14's rmse: 0.624146\tY_14's l2: 0.389558\n",
      "[0]\tvalidation_0-rmse:0.920155\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1158]\tvalidation_0-rmse:0.347636\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.674326\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[764]\tvalidation_0-rmse:0.377983\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.627229\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1078]\tvalidation_0-rmse:0.357735\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.2918\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:2.55403\n",
      "[0]\tvalidation_0-rmse:30.6697\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2388]\tvalidation_0-rmse:2.51716\n",
      "\n",
      "[0]\tvalidation_0-rmse:16.0339\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1383]\tvalidation_0-rmse:1.5499\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.67853\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2579]\tvalidation_0-rmse:0.398075\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6499\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2524]\tvalidation_0-rmse:0.627941\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6627\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2275]\tvalidation_0-rmse:0.621848\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7885\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:0.832999\n",
      "[0]\tvalidation_0-rmse:23.685\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2737]\tvalidation_0-rmse:0.801479\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.592\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2851]\tvalidation_0-rmse:0.623217\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5887\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2664]\tvalidation_0-rmse:0.624274\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6003\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2329]\tvalidation_0-rmse:0.622359\n",
      "\n",
      "========== fold 2 ==========\n",
      "CatBoostRegressor model nrmse : 1.9411\n",
      "LGBMRegressor model nrmse : 1.9430\n",
      "XGBRegressor model nrmse : 1.9367\n",
      "CAT 코드 실행 시간:        695s\n",
      "LGB 코드 실행 시간:        141s\n",
      "XGB 코드 실행 시간:        449s\n",
      "average model nrmse : 1.9342\n",
      "0:\tlearn: 4.6154140\ttest: 4.7550203\tbest: 4.7550203 (0)\ttotal: 197ms\tremaining: 16m 24s\n",
      "200:\tlearn: 4.3485865\ttest: 4.6279019\tbest: 4.6279019 (200)\ttotal: 34.7s\tremaining: 13m 47s\n",
      "400:\tlearn: 4.2095797\ttest: 4.5970779\tbest: 4.5970779 (400)\ttotal: 1m 9s\tremaining: 13m 12s\n",
      "600:\tlearn: 4.0941431\ttest: 4.5797255\tbest: 4.5796856 (598)\ttotal: 1m 42s\tremaining: 12m 32s\n",
      "800:\tlearn: 3.9906553\ttest: 4.5623475\tbest: 4.5623475 (800)\ttotal: 2m 16s\tremaining: 11m 56s\n",
      "1000:\tlearn: 3.8920792\ttest: 4.5517764\tbest: 4.5517121 (996)\ttotal: 2m 50s\tremaining: 11m 22s\n",
      "1200:\tlearn: 3.8011234\ttest: 4.5439445\tbest: 4.5439389 (1199)\ttotal: 3m 25s\tremaining: 10m 49s\n",
      "1400:\tlearn: 3.7114088\ttest: 4.5383761\tbest: 4.5383761 (1400)\ttotal: 3m 59s\tremaining: 10m 14s\n",
      "1600:\tlearn: 3.6249603\ttest: 4.5312841\tbest: 4.5312411 (1599)\ttotal: 4m 33s\tremaining: 9m 40s\n",
      "1800:\tlearn: 3.5378943\ttest: 4.5274047\tbest: 4.5274047 (1800)\ttotal: 5m 7s\tremaining: 9m 6s\n",
      "2000:\tlearn: 3.4539907\ttest: 4.5254098\tbest: 4.5253203 (1991)\ttotal: 5m 42s\tremaining: 8m 33s\n",
      "2200:\tlearn: 3.3725192\ttest: 4.5225445\tbest: 4.5224995 (2198)\ttotal: 6m 16s\tremaining: 7m 59s\n",
      "2400:\tlearn: 3.2908812\ttest: 4.5200603\tbest: 4.5199113 (2380)\ttotal: 6m 51s\tremaining: 7m 25s\n",
      "2600:\tlearn: 3.2073798\ttest: 4.5176643\tbest: 4.5175931 (2596)\ttotal: 7m 25s\tremaining: 6m 50s\n",
      "2800:\tlearn: 3.1305623\ttest: 4.5149018\tbest: 4.5147807 (2796)\ttotal: 7m 59s\tremaining: 6m 16s\n",
      "3000:\tlearn: 3.0545054\ttest: 4.5139544\tbest: 4.5139460 (2999)\ttotal: 8m 34s\tremaining: 5m 42s\n",
      "3200:\tlearn: 2.9794287\ttest: 4.5122652\tbest: 4.5120261 (3195)\ttotal: 9m 8s\tremaining: 5m 8s\n",
      "3400:\tlearn: 2.9095079\ttest: 4.5109588\tbest: 4.5109134 (3300)\ttotal: 9m 43s\tremaining: 4m 34s\n",
      "3600:\tlearn: 2.8339587\ttest: 4.5096242\tbest: 4.5093343 (3579)\ttotal: 10m 17s\tremaining: 4m\n",
      "3800:\tlearn: 2.7648440\ttest: 4.5097159\tbest: 4.5092248 (3687)\ttotal: 10m 52s\tremaining: 3m 25s\n",
      "4000:\tlearn: 2.6971699\ttest: 4.5093580\tbest: 4.5090745 (3914)\ttotal: 11m 26s\tremaining: 2m 51s\n",
      "4200:\tlearn: 2.6272546\ttest: 4.5087139\tbest: 4.5086793 (4197)\ttotal: 12m 1s\tremaining: 2m 17s\n",
      "4400:\tlearn: 2.5598125\ttest: 4.5080019\tbest: 4.5078122 (4384)\ttotal: 12m 36s\tremaining: 1m 42s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.507812248\n",
      "bestIteration = 4384\n",
      "\n",
      "Shrink model to first 4385 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[531]\tY_01's rmse: 0.344281\tY_01's l2: 0.118529\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[388]\tY_02's rmse: 0.376832\tY_02's l2: 0.142003\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[362]\tY_03's rmse: 0.352744\tY_03's l2: 0.124428\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[675]\tY_04's rmse: 2.74818\tY_04's l2: 7.55247\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[605]\tY_05's rmse: 2.4328\tY_05's l2: 5.91854\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1999]\tY_06's rmse: 1.68613\tY_06's l2: 2.84303\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[478]\tY_07's rmse: 0.408822\tY_07's l2: 0.167136\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[469]\tY_08's rmse: 0.616844\tY_08's l2: 0.380497\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[451]\tY_09's rmse: 0.614646\tY_09's l2: 0.37779\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1251]\tY_10's rmse: 0.847635\tY_10's l2: 0.718486\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[442]\tY_11's rmse: 0.798379\tY_11's l2: 0.637409\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[657]\tY_12's rmse: 0.615422\tY_12's l2: 0.378744\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[594]\tY_13's rmse: 0.61579\tY_13's l2: 0.379197\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[606]\tY_14's rmse: 0.61613\tY_14's l2: 0.379617\n",
      "[0]\tvalidation_0-rmse:0.92142\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1054]\tvalidation_0-rmse:0.343198\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.678088\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[846]\tvalidation_0-rmse:0.37632\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.625607\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1096]\tvalidation_0-rmse:0.351922\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.3915\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2091]\tvalidation_0-rmse:2.73844\n",
      "\n",
      "[0]\tvalidation_0-rmse:30.7631\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1945]\tvalidation_0-rmse:2.4261\n",
      "\n",
      "[0]\tvalidation_0-rmse:16.0554\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2471]\tvalidation_0-rmse:1.74775\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.66353\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1113]\tvalidation_0-rmse:0.408212\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6415\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2151]\tvalidation_0-rmse:0.616769\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6584\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2511]\tvalidation_0-rmse:0.613647\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7795\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2660]\tvalidation_0-rmse:0.843118\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.7064\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2297]\tvalidation_0-rmse:0.794624\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5867\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1877]\tvalidation_0-rmse:0.616384\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5835\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2453]\tvalidation_0-rmse:0.615806\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5918\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2359]\tvalidation_0-rmse:0.615437\n",
      "\n",
      "========== fold 3 ==========\n",
      "CatBoostRegressor model nrmse : 1.9510\n",
      "LGBMRegressor model nrmse : 1.9485\n",
      "XGBRegressor model nrmse : 1.9487\n",
      "CAT 코드 실행 시간:        792s\n",
      "LGB 코드 실행 시간:        124s\n",
      "XGB 코드 실행 시간:        385s\n",
      "average model nrmse : 1.9433\n",
      "0:\tlearn: 4.6469029\ttest: 4.5936744\tbest: 4.5936744 (0)\ttotal: 178ms\tremaining: 14m 50s\n",
      "200:\tlearn: 4.3726861\ttest: 4.4709098\tbest: 4.4709098 (200)\ttotal: 35.2s\tremaining: 14m\n",
      "400:\tlearn: 4.2300804\ttest: 4.4425035\tbest: 4.4425035 (400)\ttotal: 1m 9s\tremaining: 13m 22s\n",
      "600:\tlearn: 4.1189250\ttest: 4.4276086\tbest: 4.4276086 (600)\ttotal: 1m 43s\tremaining: 12m 40s\n",
      "800:\tlearn: 4.0090653\ttest: 4.4117210\tbest: 4.4117210 (800)\ttotal: 2m 17s\tremaining: 12m 1s\n",
      "1000:\tlearn: 3.9149496\ttest: 4.4033119\tbest: 4.4033056 (998)\ttotal: 2m 51s\tremaining: 11m 24s\n",
      "1200:\tlearn: 3.8242325\ttest: 4.3954408\tbest: 4.3954234 (1199)\ttotal: 3m 25s\tremaining: 10m 48s\n",
      "1400:\tlearn: 3.7356810\ttest: 4.3896211\tbest: 4.3896211 (1400)\ttotal: 3m 59s\tremaining: 10m 14s\n",
      "1600:\tlearn: 3.6466681\ttest: 4.3850557\tbest: 4.3848910 (1595)\ttotal: 4m 33s\tremaining: 9m 39s\n",
      "1800:\tlearn: 3.5610275\ttest: 4.3811429\tbest: 4.3809950 (1791)\ttotal: 5m 7s\tremaining: 9m 6s\n",
      "2000:\tlearn: 3.4748478\ttest: 4.3774704\tbest: 4.3773754 (1974)\ttotal: 5m 41s\tremaining: 8m 32s\n",
      "2200:\tlearn: 3.3923872\ttest: 4.3738385\tbest: 4.3738385 (2200)\ttotal: 6m 15s\tremaining: 7m 57s\n",
      "2400:\tlearn: 3.3113795\ttest: 4.3716332\tbest: 4.3716332 (2400)\ttotal: 6m 49s\tremaining: 7m 23s\n",
      "2600:\tlearn: 3.2259665\ttest: 4.3692024\tbest: 4.3692024 (2600)\ttotal: 7m 23s\tremaining: 6m 49s\n",
      "2800:\tlearn: 3.1484913\ttest: 4.3681220\tbest: 4.3681038 (2797)\ttotal: 7m 58s\tremaining: 6m 15s\n",
      "3000:\tlearn: 3.0708939\ttest: 4.3666663\tbest: 4.3665083 (2962)\ttotal: 8m 33s\tremaining: 5m 41s\n",
      "3200:\tlearn: 2.9959586\ttest: 4.3648817\tbest: 4.3648361 (3197)\ttotal: 9m 7s\tremaining: 5m 7s\n",
      "3400:\tlearn: 2.9188306\ttest: 4.3641946\tbest: 4.3640524 (3389)\ttotal: 9m 41s\tremaining: 4m 33s\n",
      "3600:\tlearn: 2.8443855\ttest: 4.3626594\tbest: 4.3626168 (3596)\ttotal: 10m 16s\tremaining: 3m 59s\n",
      "3800:\tlearn: 2.7700107\ttest: 4.3621205\tbest: 4.3620767 (3799)\ttotal: 10m 50s\tremaining: 3m 25s\n",
      "4000:\tlearn: 2.7017708\ttest: 4.3607175\tbest: 4.3605843 (3991)\ttotal: 11m 26s\tremaining: 2m 51s\n",
      "4200:\tlearn: 2.6306618\ttest: 4.3604483\tbest: 4.3603169 (4194)\ttotal: 12m 2s\tremaining: 2m 17s\n",
      "4400:\tlearn: 2.5636790\ttest: 4.3594103\tbest: 4.3594103 (4400)\ttotal: 12m 37s\tremaining: 1m 43s\n",
      "4600:\tlearn: 2.4964996\ttest: 4.3601794\tbest: 4.3593107 (4413)\ttotal: 13m 11s\tremaining: 1m 8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.359310718\n",
      "bestIteration = 4413\n",
      "\n",
      "Shrink model to first 4414 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[370]\tY_01's rmse: 0.340128\tY_01's l2: 0.115687\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[456]\tY_02's rmse: 0.375074\tY_02's l2: 0.14068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[359]\tY_03's rmse: 0.347997\tY_03's l2: 0.121102\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1124]\tY_04's rmse: 2.50417\tY_04's l2: 6.27084\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[723]\tY_05's rmse: 2.45733\tY_05's l2: 6.03848\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[565]\tY_06's rmse: 1.75725\tY_06's l2: 3.08792\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[690]\tY_07's rmse: 0.406903\tY_07's l2: 0.16557\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[690]\tY_08's rmse: 0.621945\tY_08's l2: 0.386816\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[634]\tY_09's rmse: 0.613333\tY_09's l2: 0.376177\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1076]\tY_10's rmse: 0.854934\tY_10's l2: 0.730912\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[829]\tY_11's rmse: 0.801289\tY_11's l2: 0.642065\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[605]\tY_12's rmse: 0.618297\tY_12's l2: 0.382291\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[812]\tY_13's rmse: 0.616638\tY_13's l2: 0.380242\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[595]\tY_14's rmse: 0.617314\tY_14's l2: 0.381077\n",
      "[0]\tvalidation_0-rmse:0.922522\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[889]\tvalidation_0-rmse:0.339685\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.6782\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[867]\tvalidation_0-rmse:0.374434\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.626358\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[894]\tvalidation_0-rmse:0.347557\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.3277\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2329]\tvalidation_0-rmse:2.48802\n",
      "\n",
      "[0]\tvalidation_0-rmse:30.7219\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2189]\tvalidation_0-rmse:2.45242\n",
      "\n",
      "[0]\tvalidation_0-rmse:16.062\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2161]\tvalidation_0-rmse:1.74211\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.66718\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2319]\tvalidation_0-rmse:0.405698\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.631\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1908]\tvalidation_0-rmse:0.620804\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6424\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2467]\tvalidation_0-rmse:0.613163\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7622\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:0.848001\n",
      "[0]\tvalidation_0-rmse:23.715\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:0.798782\n",
      "[0]\tvalidation_0-rmse:26.5763\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2429]\tvalidation_0-rmse:0.617103\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5689\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:0.614816\n",
      "[0]\tvalidation_0-rmse:26.584\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2302]\tvalidation_0-rmse:0.616114\n",
      "\n",
      "========== fold 4 ==========\n",
      "CatBoostRegressor model nrmse : 1.9174\n",
      "LGBMRegressor model nrmse : 1.9194\n",
      "XGBRegressor model nrmse : 1.9140\n",
      "CAT 코드 실행 시간:        798s\n",
      "LGB 코드 실행 시간:        126s\n",
      "XGB 코드 실행 시간:        431s\n",
      "average model nrmse : 1.9110\n",
      "0:\tlearn: 4.6428739\ttest: 4.6184157\tbest: 4.6184157 (0)\ttotal: 189ms\tremaining: 15m 43s\n",
      "200:\tlearn: 4.3702027\ttest: 4.4868281\tbest: 4.4868281 (200)\ttotal: 35.4s\tremaining: 14m 5s\n",
      "400:\tlearn: 4.2342891\ttest: 4.4567794\tbest: 4.4567794 (400)\ttotal: 1m 9s\tremaining: 13m 18s\n",
      "600:\tlearn: 4.1174906\ttest: 4.4378020\tbest: 4.4378020 (600)\ttotal: 1m 44s\tremaining: 12m 42s\n",
      "800:\tlearn: 4.0093655\ttest: 4.4241087\tbest: 4.4241087 (800)\ttotal: 2m 18s\tremaining: 12m 6s\n",
      "1000:\tlearn: 3.9086390\ttest: 4.4126940\tbest: 4.4126427 (990)\ttotal: 2m 52s\tremaining: 11m 28s\n",
      "1200:\tlearn: 3.8190844\ttest: 4.4057802\tbest: 4.4057802 (1200)\ttotal: 3m 26s\tremaining: 10m 52s\n",
      "1400:\tlearn: 3.7286050\ttest: 4.3996759\tbest: 4.3996442 (1399)\ttotal: 4m\tremaining: 10m 18s\n",
      "1600:\tlearn: 3.6405091\ttest: 4.3939954\tbest: 4.3939873 (1598)\ttotal: 4m 35s\tremaining: 9m 44s\n",
      "1800:\tlearn: 3.5561743\ttest: 4.3907751\tbest: 4.3907342 (1790)\ttotal: 5m 10s\tremaining: 9m 10s\n",
      "2000:\tlearn: 3.4742912\ttest: 4.3876901\tbest: 4.3876901 (2000)\ttotal: 5m 45s\tremaining: 8m 38s\n",
      "2200:\tlearn: 3.3906615\ttest: 4.3853221\tbest: 4.3851894 (2196)\ttotal: 6m 20s\tremaining: 8m 3s\n",
      "2400:\tlearn: 3.3112940\ttest: 4.3825942\tbest: 4.3825942 (2400)\ttotal: 6m 55s\tremaining: 7m 29s\n",
      "2600:\tlearn: 3.2329678\ttest: 4.3812851\tbest: 4.3812182 (2598)\ttotal: 7m 30s\tremaining: 6m 55s\n",
      "2800:\tlearn: 3.1545498\ttest: 4.3803622\tbest: 4.3802554 (2791)\ttotal: 8m 5s\tremaining: 6m 20s\n",
      "3000:\tlearn: 3.0797333\ttest: 4.3782538\tbest: 4.3782538 (3000)\ttotal: 8m 39s\tremaining: 5m 45s\n",
      "3200:\tlearn: 3.0015641\ttest: 4.3771150\tbest: 4.3771110 (3190)\ttotal: 9m 13s\tremaining: 5m 11s\n",
      "3400:\tlearn: 2.9272134\ttest: 4.3755871\tbest: 4.3754201 (3393)\ttotal: 9m 48s\tremaining: 4m 36s\n",
      "3600:\tlearn: 2.8510680\ttest: 4.3757098\tbest: 4.3750595 (3459)\ttotal: 10m 22s\tremaining: 4m 2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.375059542\n",
      "bestIteration = 3459\n",
      "\n",
      "Shrink model to first 3460 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[313]\tY_01's rmse: 0.343926\tY_01's l2: 0.118285\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[403]\tY_02's rmse: 0.376507\tY_02's l2: 0.141758\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[315]\tY_03's rmse: 0.352108\tY_03's l2: 0.12398\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1124]\tY_04's rmse: 2.51843\tY_04's l2: 6.34247\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1200]\tY_05's rmse: 2.47069\tY_05's l2: 6.10432\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[358]\tY_06's rmse: 1.77252\tY_06's l2: 3.14183\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[715]\tY_07's rmse: 0.4094\tY_07's l2: 0.167609\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[374]\tY_08's rmse: 0.617961\tY_08's l2: 0.381876\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[571]\tY_09's rmse: 0.61492\tY_09's l2: 0.378127\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1158]\tY_10's rmse: 0.852825\tY_10's l2: 0.727311\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[905]\tY_11's rmse: 0.805105\tY_11's l2: 0.648194\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[434]\tY_12's rmse: 0.613998\tY_12's l2: 0.376994\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[545]\tY_13's rmse: 0.61341\tY_13's l2: 0.376271\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[380]\tY_14's rmse: 0.616373\tY_14's l2: 0.379915\n",
      "[0]\tvalidation_0-rmse:0.919973\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[890]\tvalidation_0-rmse:0.343522\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.67518\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[786]\tvalidation_0-rmse:0.375159\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.626702\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[832]\tvalidation_0-rmse:0.351457\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.2978\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:2.50424\n",
      "[0]\tvalidation_0-rmse:30.7084\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[2999]\tvalidation_0-rmse:2.46682\n",
      "[0]\tvalidation_0-rmse:16.0463\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1143]\tvalidation_0-rmse:1.77167\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.67043\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1406]\tvalidation_0-rmse:0.409119\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6506\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2126]\tvalidation_0-rmse:0.616656\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.663\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2096]\tvalidation_0-rmse:0.612694\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7883\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2060]\tvalidation_0-rmse:0.851854\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.6967\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2808]\tvalidation_0-rmse:0.803099\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5911\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2073]\tvalidation_0-rmse:0.612082\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.589\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2023]\tvalidation_0-rmse:0.610916\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.601\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1830]\tvalidation_0-rmse:0.614661\n",
      "\n",
      "========== fold 5 ==========\n",
      "CatBoostRegressor model nrmse : 1.9299\n",
      "LGBMRegressor model nrmse : 1.9375\n",
      "XGBRegressor model nrmse : 1.9328\n",
      "CAT 코드 실행 시간:        637s\n",
      "LGB 코드 실행 시간:        121s\n",
      "XGB 코드 실행 시간:        372s\n",
      "average model nrmse : 1.9281\n",
      "0:\tlearn: 4.6483836\ttest: 4.5787949\tbest: 4.5787949 (0)\ttotal: 195ms\tremaining: 16m 16s\n",
      "200:\tlearn: 4.3830468\ttest: 4.4559705\tbest: 4.4559705 (200)\ttotal: 34.7s\tremaining: 13m 48s\n",
      "400:\tlearn: 4.2436593\ttest: 4.4244184\tbest: 4.4244184 (400)\ttotal: 1m 9s\tremaining: 13m 13s\n",
      "600:\tlearn: 4.1310248\ttest: 4.4078791\tbest: 4.4078241 (598)\ttotal: 1m 44s\tremaining: 12m 41s\n",
      "800:\tlearn: 4.0224397\ttest: 4.3936625\tbest: 4.3936625 (800)\ttotal: 2m 18s\tremaining: 12m 3s\n",
      "1000:\tlearn: 3.9247720\ttest: 4.3838441\tbest: 4.3838249 (999)\ttotal: 2m 52s\tremaining: 11m 28s\n",
      "1200:\tlearn: 3.8258187\ttest: 4.3763794\tbest: 4.3763455 (1199)\ttotal: 3m 26s\tremaining: 10m 53s\n",
      "1400:\tlearn: 3.7316505\ttest: 4.3692613\tbest: 4.3692613 (1400)\ttotal: 4m 1s\tremaining: 10m 19s\n",
      "1600:\tlearn: 3.6428308\ttest: 4.3650313\tbest: 4.3648952 (1597)\ttotal: 4m 36s\tremaining: 9m 46s\n",
      "1800:\tlearn: 3.5558640\ttest: 4.3628598\tbest: 4.3627531 (1797)\ttotal: 5m 10s\tremaining: 9m 12s\n",
      "2000:\tlearn: 3.4701036\ttest: 4.3593942\tbest: 4.3593373 (1993)\ttotal: 5m 45s\tremaining: 8m 38s\n",
      "2200:\tlearn: 3.3905595\ttest: 4.3561424\tbest: 4.3561424 (2200)\ttotal: 6m 21s\tremaining: 8m 5s\n",
      "2400:\tlearn: 3.3118383\ttest: 4.3556842\tbest: 4.3555542 (2393)\ttotal: 6m 56s\tremaining: 7m 31s\n",
      "2600:\tlearn: 3.2322895\ttest: 4.3540755\tbest: 4.3539143 (2593)\ttotal: 7m 31s\tremaining: 6m 56s\n",
      "2800:\tlearn: 3.1535952\ttest: 4.3525138\tbest: 4.3522351 (2735)\ttotal: 8m 6s\tremaining: 6m 21s\n",
      "3000:\tlearn: 3.0780286\ttest: 4.3516983\tbest: 4.3516293 (2980)\ttotal: 8m 41s\tremaining: 5m 47s\n",
      "3200:\tlearn: 3.0030503\ttest: 4.3509946\tbest: 4.3509866 (3161)\ttotal: 9m 16s\tremaining: 5m 12s\n",
      "3400:\tlearn: 2.9257425\ttest: 4.3508192\tbest: 4.3504366 (3319)\ttotal: 9m 51s\tremaining: 4m 37s\n",
      "3600:\tlearn: 2.8550961\ttest: 4.3495078\tbest: 4.3494011 (3593)\ttotal: 10m 26s\tremaining: 4m 3s\n",
      "3800:\tlearn: 2.7822804\ttest: 4.3487967\tbest: 4.3487024 (3798)\ttotal: 11m\tremaining: 3m 28s\n",
      "4000:\tlearn: 2.7120236\ttest: 4.3487486\tbest: 4.3485102 (3975)\ttotal: 11m 35s\tremaining: 2m 53s\n",
      "4200:\tlearn: 2.6420218\ttest: 4.3483684\tbest: 4.3483190 (4198)\ttotal: 12m 10s\tremaining: 2m 18s\n",
      "4400:\tlearn: 2.5724406\ttest: 4.3480109\tbest: 4.3477031 (4354)\ttotal: 12m 46s\tremaining: 1m 44s\n",
      "4600:\tlearn: 2.5083526\ttest: 4.3478399\tbest: 4.3476732 (4430)\ttotal: 13m 20s\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 4.347673179\n",
      "bestIteration = 4430\n",
      "\n",
      "Shrink model to first 4431 iterations.\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[480]\tY_01's rmse: 0.347391\tY_01's l2: 0.120681\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[667]\tY_02's rmse: 0.377453\tY_02's l2: 0.142471\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[313]\tY_03's rmse: 0.353905\tY_03's l2: 0.125249\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1172]\tY_04's rmse: 2.49783\tY_04's l2: 6.23913\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[656]\tY_05's rmse: 2.45364\tY_05's l2: 6.02034\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1528]\tY_06's rmse: 1.67313\tY_06's l2: 2.79935\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[825]\tY_07's rmse: 0.406092\tY_07's l2: 0.16491\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[848]\tY_08's rmse: 0.624206\tY_08's l2: 0.389633\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[533]\tY_09's rmse: 0.62071\tY_09's l2: 0.385281\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1037]\tY_10's rmse: 0.845447\tY_10's l2: 0.714781\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[588]\tY_11's rmse: 0.806539\tY_11's l2: 0.650505\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[593]\tY_12's rmse: 0.619833\tY_12's l2: 0.384193\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[470]\tY_13's rmse: 0.61936\tY_13's l2: 0.383606\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[519]\tY_14's rmse: 0.622707\tY_14's l2: 0.387764\n",
      "[0]\tvalidation_0-rmse:0.914518\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1079]\tvalidation_0-rmse:0.346979\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.669695\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[841]\tvalidation_0-rmse:0.376919\n",
      "\n",
      "[0]\tvalidation_0-rmse:0.621079\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[846]\tvalidation_0-rmse:0.353279\n",
      "\n",
      "[0]\tvalidation_0-rmse:13.2426\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1752]\tvalidation_0-rmse:2.50237\n",
      "\n",
      "[0]\tvalidation_0-rmse:30.6747\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1995]\tvalidation_0-rmse:2.44482\n",
      "\n",
      "[0]\tvalidation_0-rmse:16.0262\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1780]\tvalidation_0-rmse:1.67334\n",
      "\n",
      "[0]\tvalidation_0-rmse:2.68081\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1726]\tvalidation_0-rmse:0.405087\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6505\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2218]\tvalidation_0-rmse:0.622353\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6646\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2668]\tvalidation_0-rmse:0.617708\n",
      "\n",
      "[0]\tvalidation_0-rmse:22.7964\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2408]\tvalidation_0-rmse:0.840447\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.678\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2160]\tvalidation_0-rmse:0.805208\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5946\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2411]\tvalidation_0-rmse:0.618498\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.5912\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[2305]\tvalidation_0-rmse:0.617839\n",
      "\n",
      "[0]\tvalidation_0-rmse:26.6043\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1712]\tvalidation_0-rmse:0.622072\n",
      "\n",
      "========== fold 6 ==========\n",
      "CatBoostRegressor model nrmse : 1.9437\n",
      "LGBMRegressor model nrmse : 1.9421\n",
      "XGBRegressor model nrmse : 1.9395\n",
      "CAT 코드 실행 시간:        809s\n",
      "LGB 코드 실행 시간:        131s\n",
      "XGB 코드 실행 시간:        371s\n",
      "average model nrmse : 1.9351\n",
      "==============================\n",
      "Model Sum Average nrmse 1.9311\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "import lightgbm\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 6, random_state = 42, shuffle = True) #총 6번의 fold 진행\n",
    "n = 0 #x번째 fold인지 기록\n",
    "\n",
    "fold_target_pred = []\n",
    "fold_score = []\n",
    "\n",
    "drop_x = [\"X_02\", \"X_10\",\"X_11\", \"X_34\", \"X_35\", \"X_36\", \"X_37\",\"X_45\"]\n",
    "\n",
    "#파일 디렉토리 생성\n",
    "model_dir = f'./model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for train_index, valid_index in skf.split(data_train_X, data_train_y['label']): #label 기준으로 stratified k fold 진행\n",
    "    n += 1\n",
    "    \n",
    "    val_pred_name = [] #validation pred model 이름 저장\n",
    "    val_pred = []      #validation set pred 결과 저장\n",
    "    target_pred = []   #test set pred 결과 저장\n",
    "    \n",
    "    train_X = np.array(data_train_X.drop(drop_x, axis = 1))\n",
    "    train_Y = np.array(data_train_y.drop(['label'], axis = 1)) # 분배된 학습을 위해 만들어뒀던 label feature 제거\n",
    "    label_Y = np.array(data_train_y['label']) # label값만 가지는 데이터\n",
    "    \n",
    "    X_train, X_valid = train_X[train_index], train_X[valid_index]\n",
    "    y_train, y_valid = train_Y[train_index], train_Y[valid_index]\n",
    "    \n",
    "    y_label = label_Y[train_index]\n",
    "\n",
    "    X_test = np.array(data_test.drop(drop_x, axis = 1))\n",
    "    \n",
    "    ### Create Model ###\n",
    "    #CAT model\n",
    "    start_time_cat = time.time()\n",
    "    model_cat = CatBoostRegressor(verbose = 200,\n",
    "                            learning_rate = 0.02,\n",
    "                            random_seed = 42,\n",
    "                            iterations = 5000,\n",
    "                            loss_function='MultiRMSE',\n",
    "                            #ignored_features = [8, 9, 31, 32, 33, 34, 45, 50, 51, 53, 54, 55],\n",
    "                            od_wait = 200,\n",
    "                            depth = 9)\n",
    "    \n",
    "    model_cat.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
    "    end_time_cat = time.time()\n",
    "    \n",
    "    \n",
    "    #model cat 저장\n",
    "    cat_path = './model/cat_{}'.format(n)\n",
    "    model_cat.save_model(cat_path)\n",
    "    \n",
    "    #model cat 불러오기\n",
    "    #model_cat.load_model(cat_path)\n",
    "    \n",
    "    val_pred_name.append(\"CatBoostRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_cat.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_cat.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    ### LGBM model\n",
    "    start_time_lgb = time.time()\n",
    "    model_lgbm = MyMultiOutputRegressor_LGBM(LGBMRegressor(n_estimators = 2000, \n",
    "                                               learning_rate = 0.01,\n",
    "                                               max_depth = 16,\n",
    "                                               min_child_samples = 56,\n",
    "                                               subsample = 0.4,\n",
    "                                               num_leaves = 160,\n",
    "                                               random_state = 42,\n",
    "                                               n_jobs = 8))\n",
    "\n",
    "    fit_params = dict(\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric = \"rmse\",\n",
    "        )\n",
    "\n",
    "    model_lgbm.fit(X_train, y_train, **fit_params)\n",
    "    end_time_lgb = time.time()\n",
    "    val_pred_name.append(\"LGBMRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_lgbm.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_lgbm.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    #model lgbm 저장\n",
    "    lgbm_path = './model/lgbm_{}'.format(n)\n",
    "    model_lgbm.save(lgbm_path)\n",
    "    \n",
    "    #model lgbm 불러오기\n",
    "    #model_lgbm.load(lgbm_path)\n",
    "\n",
    "    ### XGB model\n",
    "    start_time_xgb = time.time()\n",
    "    model_xgb = MyMultiOutputRegressor_XGB(XGBRegressor(objective = \"reg:squarederror\",\n",
    "                                                  n_estimators = 3000,\n",
    "                                                  random_state = 42,\n",
    "                                                  eval_metric = \"rmse\", \n",
    "                                                  learning_rate=0.006,\n",
    "                                                  subsample=0.75, \n",
    "                                                  colsample_bytree = 0.86,\n",
    "                                                  max_depth=9,\n",
    "                                                  tree_method='gpu_hist', \n",
    "                                                  gpu_id = 0))\n",
    "    \n",
    "    fit_params = dict(\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        )\n",
    "    \n",
    "    model_xgb.fit(X_train, y_train, **fit_params)\n",
    "    end_time_xgb = time.time()\n",
    "    val_pred_name.append(\"XGBRegressor\")  # 모델 이름 저장\n",
    "    val_pred.append(model_xgb.predict(X_valid))   # validation set pred 결과 저장\n",
    "    target_pred.append(model_xgb.predict(X_test)) # test set pred 결과 저장\n",
    "    \n",
    "    #model xgb 저장\n",
    "    xgb_path = './model/xgb_{}'.format(n)\n",
    "    model_xgb.save(xgb_path)\n",
    "    \n",
    "    #model xgb 불러오기\n",
    "    #model_xgb.load(xgb_path)\n",
    "  \n",
    "    ### average validation pred ###\n",
    "    preds = np.array(val_pred[0])\n",
    "    for i in range(1, len(val_pred)):\n",
    "        preds += val_pred[i]\n",
    "    preds = preds/len(val_pred)\n",
    "\n",
    "    ### average target pred ###\n",
    "    target_preds = target_pred[0]\n",
    "    for i in range(1, len(target_pred)):\n",
    "        target_preds += target_pred[i]\n",
    "    target_preds = target_preds/len(target_pred)\n",
    "    fold_target_pred.append(target_preds) # append final target pred\n",
    "    \n",
    "    print(\"========== fold %d ==========\" %(n))\n",
    "    for i in range(len(val_pred)):\n",
    "        print(\"%s model nrmse : %0.4f\" %(val_pred_name[i], lg_nrmse(y_valid, val_pred[i])))\n",
    "        \n",
    "    print('CAT 코드 실행 시간: %10ds' % (end_time_cat - start_time_cat))\n",
    "    print('LGB 코드 실행 시간: %10ds' % (end_time_lgb - start_time_lgb))\n",
    "    print('XGB 코드 실행 시간: %10ds' % (end_time_xgb - start_time_xgb))\n",
    "    print(\"average model nrmse : %0.4f\" %(lg_nrmse(y_valid, preds)))\n",
    "    fold_score.append(lg_nrmse(y_valid, preds))\n",
    "\n",
    "total_score = fold_score[0]\n",
    "for i in range(1, len(fold_score)):\n",
    "    total_score += fold_score[i]\n",
    "    \n",
    "total_score = total_score/len(fold_score)\n",
    "\n",
    "print(\"==============================\")\n",
    "print(\"Model Sum Average nrmse %0.4f\" %(total_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIC5ywVP-RPu"
   },
   "source": [
    "# 결과 제출\n",
    "6 cv soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.380886Z",
     "iopub.status.busy": "2022-09-04T08:36:50.380366Z",
     "iopub.status.idle": "2022-09-04T08:36:50.387292Z",
     "shell.execute_reply": "2022-09-04T08:36:50.386786Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.380869Z"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1660337628984,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "wRSu68HAVPpt"
   },
   "outputs": [],
   "source": [
    "final_pred = np.array(fold_target_pred[0])\n",
    "\n",
    "for i in range(1, 6):\n",
    "    final_pred += fold_target_pred[i]\n",
    "\n",
    "final_pred = final_pred/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.388385Z",
     "iopub.status.busy": "2022-09-04T08:36:50.388190Z",
     "iopub.status.idle": "2022-09-04T08:36:50.392316Z",
     "shell.execute_reply": "2022-09-04T08:36:50.391796Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.388370Z"
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1660337635922,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "skTfQy-vqlAJ",
    "outputId": "b277e675-9160-4b2a-9668-d110be745b2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.43650797,   1.24628275,   1.12990453, ..., -25.94147077,\n",
       "        -25.93628909, -25.98553301],\n",
       "       [  1.50875523,   1.23834255,   1.15887145, ..., -26.11785189,\n",
       "        -26.14873015, -26.13291365],\n",
       "       [  1.49355102,   1.18278801,   1.12252219, ..., -25.81403033,\n",
       "        -25.7876382 , -25.7702005 ],\n",
       "       ...,\n",
       "       [  1.23594559,   0.91828441,   0.97499806, ..., -26.4815955 ,\n",
       "        -26.4747848 , -26.50836623],\n",
       "       [  1.20143511,   0.84251556,   0.92003249, ..., -26.41303087,\n",
       "        -26.42648215, -26.45366266],\n",
       "       [  1.29571369,   0.97338884,   1.0084016 , ..., -26.57056884,\n",
       "        -26.55470405, -26.57788576]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98YK7PKo_vpH"
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.394059Z",
     "iopub.status.busy": "2022-09-04T08:36:50.393895Z",
     "iopub.status.idle": "2022-09-04T08:36:50.488262Z",
     "shell.execute_reply": "2022-09-04T08:36:50.487776Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.394045Z"
    },
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1660337643060,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "awktTtKFVcPx",
    "outputId": "2fc23729-2c53-4c71-ffb3-ffff38de7828"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Y_01  Y_02  Y_03  Y_04  Y_05  Y_06  Y_07  Y_08  Y_09  Y_10  \\\n",
       "0  TEST_00001     0     0     0     0     0     0     0     0     0     0   \n",
       "1  TEST_00002     0     0     0     0     0     0     0     0     0     0   \n",
       "2  TEST_00003     0     0     0     0     0     0     0     0     0     0   \n",
       "3  TEST_00004     0     0     0     0     0     0     0     0     0     0   \n",
       "4  TEST_00005     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   Y_11  Y_12  Y_13  Y_14  \n",
       "0     0     0     0     0  \n",
       "1     0     0     0     0  \n",
       "2     0     0     0     0  \n",
       "3     0     0     0     0  \n",
       "4     0     0     0     0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './sample_submission.csv'\n",
    "sample_submission = pd.read_csv(filename)\n",
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.491929Z",
     "iopub.status.busy": "2022-09-04T08:36:50.491792Z",
     "iopub.status.idle": "2022-09-04T08:36:50.508403Z",
     "shell.execute_reply": "2022-09-04T08:36:50.507929Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.491915Z"
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1660337650888,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "LwLJSA7YqlGe",
    "outputId": "c230adf5-f641-4591-deb6-f1aea5e1b656"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1.436508</td>\n",
       "      <td>1.246283</td>\n",
       "      <td>1.129905</td>\n",
       "      <td>14.188473</td>\n",
       "      <td>31.280681</td>\n",
       "      <td>16.680478</td>\n",
       "      <td>3.115658</td>\n",
       "      <td>-26.008348</td>\n",
       "      <td>-26.026714</td>\n",
       "      <td>-22.132417</td>\n",
       "      <td>24.607211</td>\n",
       "      <td>-25.941471</td>\n",
       "      <td>-25.936289</td>\n",
       "      <td>-25.985533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1.508755</td>\n",
       "      <td>1.238343</td>\n",
       "      <td>1.158871</td>\n",
       "      <td>13.063973</td>\n",
       "      <td>30.682600</td>\n",
       "      <td>16.515653</td>\n",
       "      <td>3.213386</td>\n",
       "      <td>-26.186201</td>\n",
       "      <td>-26.179164</td>\n",
       "      <td>-22.438306</td>\n",
       "      <td>24.230160</td>\n",
       "      <td>-26.117852</td>\n",
       "      <td>-26.148730</td>\n",
       "      <td>-26.132914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1.493551</td>\n",
       "      <td>1.182788</td>\n",
       "      <td>1.122522</td>\n",
       "      <td>14.668821</td>\n",
       "      <td>32.125480</td>\n",
       "      <td>16.925155</td>\n",
       "      <td>3.028501</td>\n",
       "      <td>-25.838927</td>\n",
       "      <td>-25.844483</td>\n",
       "      <td>-21.944534</td>\n",
       "      <td>24.660105</td>\n",
       "      <td>-25.814030</td>\n",
       "      <td>-25.787638</td>\n",
       "      <td>-25.770201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1.446701</td>\n",
       "      <td>1.189539</td>\n",
       "      <td>1.057934</td>\n",
       "      <td>15.040722</td>\n",
       "      <td>32.612210</td>\n",
       "      <td>17.226454</td>\n",
       "      <td>3.075741</td>\n",
       "      <td>-25.633640</td>\n",
       "      <td>-25.650345</td>\n",
       "      <td>-21.715864</td>\n",
       "      <td>25.009979</td>\n",
       "      <td>-25.607663</td>\n",
       "      <td>-25.609216</td>\n",
       "      <td>-25.620737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00005</td>\n",
       "      <td>1.360789</td>\n",
       "      <td>1.007224</td>\n",
       "      <td>0.961567</td>\n",
       "      <td>14.810293</td>\n",
       "      <td>31.456541</td>\n",
       "      <td>16.940240</td>\n",
       "      <td>3.164222</td>\n",
       "      <td>-25.658716</td>\n",
       "      <td>-25.691876</td>\n",
       "      <td>-22.107019</td>\n",
       "      <td>24.702687</td>\n",
       "      <td>-25.598848</td>\n",
       "      <td>-25.599207</td>\n",
       "      <td>-25.599415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID      Y_01      Y_02      Y_03       Y_04       Y_05       Y_06  \\\n",
       "0  TEST_00001  1.436508  1.246283  1.129905  14.188473  31.280681  16.680478   \n",
       "1  TEST_00002  1.508755  1.238343  1.158871  13.063973  30.682600  16.515653   \n",
       "2  TEST_00003  1.493551  1.182788  1.122522  14.668821  32.125480  16.925155   \n",
       "3  TEST_00004  1.446701  1.189539  1.057934  15.040722  32.612210  17.226454   \n",
       "4  TEST_00005  1.360789  1.007224  0.961567  14.810293  31.456541  16.940240   \n",
       "\n",
       "       Y_07       Y_08       Y_09       Y_10       Y_11       Y_12       Y_13  \\\n",
       "0  3.115658 -26.008348 -26.026714 -22.132417  24.607211 -25.941471 -25.936289   \n",
       "1  3.213386 -26.186201 -26.179164 -22.438306  24.230160 -26.117852 -26.148730   \n",
       "2  3.028501 -25.838927 -25.844483 -21.944534  24.660105 -25.814030 -25.787638   \n",
       "3  3.075741 -25.633640 -25.650345 -21.715864  25.009979 -25.607663 -25.609216   \n",
       "4  3.164222 -25.658716 -25.691876 -22.107019  24.702687 -25.598848 -25.599207   \n",
       "\n",
       "        Y_14  \n",
       "0 -25.985533  \n",
       "1 -26.132914  \n",
       "2 -25.770201  \n",
       "3 -25.620737  \n",
       "4 -25.599415  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, col in enumerate(sample_submission.columns):\n",
    "    if col=='ID':\n",
    "        continue\n",
    "    sample_submission[col] = final_pred[:,idx-1]\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T08:36:50.509528Z",
     "iopub.status.busy": "2022-09-04T08:36:50.509160Z",
     "iopub.status.idle": "2022-09-04T08:36:51.514580Z",
     "shell.execute_reply": "2022-09-04T08:36:51.514002Z",
     "shell.execute_reply.started": "2022-09-04T08:36:50.509512Z"
    },
    "executionInfo": {
     "elapsed": 1628,
     "status": "ok",
     "timestamp": 1660337680866,
     "user": {
      "displayName": "‍김세현[ 학부재학 / 전기전자공학부 ]",
      "userId": "09479150229632953696"
     },
     "user_tz": -540
    },
    "id": "Zfc0iZnUrPs6"
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('./final_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T08:54:36.558508Z",
     "iopub.status.busy": "2022-09-04T08:54:36.557730Z",
     "iopub.status.idle": "2022-09-04T08:54:45.475076Z",
     "shell.execute_reply": "2022-09-04T08:54:45.471437Z",
     "shell.execute_reply.started": "2022-09-04T08:54:36.558486Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "model_paths = sorted(glob.glob('./model/*'))\n",
    "\n",
    "import zipfile\n",
    "submission = zipfile.ZipFile(\"./model.zip\", 'w')\n",
    "for path in model_paths:\n",
    "    submission.write(path)\n",
    "submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lg_antenna_ensemble.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c239fde4eb24d585007cef1e495495261fb6bbf5570e219d9bc38ff69d41be2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
